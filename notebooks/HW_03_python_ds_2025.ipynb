{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aca0353b",
      "metadata": {
        "id": "aca0353b"
      },
      "source": [
        "# Домашнее задание 3. Парсинг, Git и тестирование на Python\n",
        "\n",
        "**Цели задания:**\n",
        "\n",
        "* Освоить базовые подходы к web-scraping с библиотеками `requests` и `BeautisulSoup`: навигация по страницам, извлечение HTML-элементов, парсинг.\n",
        "* Научиться автоматизировать задачи с использованием библиотеки `schedule`.\n",
        "* Попрактиковаться в использовании Git и оформлении проектов на GitHub.\n",
        "* Написать и запустить простые юнит-тесты с использованием `pytest`.\n",
        "\n",
        "\n",
        "В этом домашнем задании вы разработаете систему для автоматического сбора данных о книгах с сайта [Books to Scrape](http://books.toscrape.com). Нужно реализовать функции для парсинга всех страниц сайта, извлечения информации о книгах, автоматического ежедневного запуска задачи и сохранения результата.\n",
        "\n",
        "Важной частью задания станет оформление проекта: вы создадите репозиторий на GitHub, оформите `README.md`, добавите артефакты (код, данные, отчеты) и напишете базовые тесты на `pytest`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K3JMV0qwmA_q",
      "metadata": {
        "id": "K3JMV0qwmA_q"
      },
      "outputs": [],
      "source": [
        "! pip install -q schedule pytest # установка библиотек, если ещё не"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "873d4904",
      "metadata": {
        "id": "873d4904"
      },
      "outputs": [],
      "source": [
        "# Библиотеки, которые могут вам понадобиться\n",
        "# При необходимости расширяйте список\n",
        "import time\n",
        "import requests\n",
        "import schedule\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Tag\n",
        "import re\n",
        "import cProfile\n",
        "from tqdm import tqdm\n",
        "import threading\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unTvsWaegHdj",
      "metadata": {
        "id": "unTvsWaegHdj"
      },
      "source": [
        "## Задание 1. Сбор данных об одной книге (20 баллов)\n",
        "\n",
        "В этом задании мы начнем подготовку скрипта для парсинга информации о книгах со страниц каталога сайта [Books to Scrape](https://books.toscrape.com/).\n",
        "\n",
        "Для начала реализуйте функцию `get_book_data`, которая будет получать данные о книге с одной страницы (например, с [этой](http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html)). Соберите всю информацию, включая название, цену, рейтинг, количество в наличии, описание и дополнительные характеристики из таблицы Product Information. Результат достаточно вернуть в виде словаря.\n",
        "\n",
        "**Не забывайте про соблюдение PEP-8** — помимо качественно написанного кода важно также документировать функции по стандарту:\n",
        "* кратко описать, что она делает и для чего нужна;\n",
        "* какие входные аргументы принимает, какого они типа и что означают по смыслу;\n",
        "* аналогично описать возвращаемые значения.\n",
        "\n",
        "*P. S. Состав, количество аргументов функции и тип возвращаемого значения можете менять как вам удобно. То, что написано ниже в шаблоне — лишь пример.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "UfD2vAjHkEoS",
      "metadata": {
        "id": "UfD2vAjHkEoS"
      },
      "outputs": [],
      "source": [
        "\n",
        "_number_pattern    = re.compile('[\\d.]+') # Паттерн поиска числа\n",
        "_rating_pattern    = re.compile('star-rating .*') # Паттерн поиска строкового значения рейтинги(One, Two, etc.)\n",
        "_main_data_pattern = re.compile('.* product_main') # Паттерн поиска имени класса основных данных книги\n",
        "\n",
        "def get_tag(context: Tag, tag_name: str, class_name: str|re.Pattern = '') -> Tag|None:\n",
        "   \"\"\"\n",
        "   Находит объект Tag с указанным именем и классом в переданном контексте.\n",
        "    \n",
        "    Args:\n",
        "        context (Tag): Объект bs4.element.Tag, в котором осуществляется поиск\n",
        "        tag_name (str): Название HTML-тега для поиска (например, 'div', 'span', 'a')\n",
        "        class_name (str|re.Pattern, optional): Название класса или регулярное выражение \n",
        "                                              для поиска по классу. По умолчанию ''.\n",
        "    \n",
        "    Returns:\n",
        "        Tag|None: Первый найденный тег, соответствующий критериям, или None если тег не найден\n",
        "                  или найденный объект не является тегом.\n",
        "    \"\"\"\n",
        "  \n",
        "   tag = context.find(tag_name, class_=class_name) if class_name else context.find(tag_name, class_=None)\n",
        "   return tag if type(tag) == Tag else None\n",
        "\n",
        "\n",
        "\n",
        "def _set_dict_value(data: dict[str, str|int|float], key: str, element: Tag|None, data_type: str) -> None:\n",
        "   \"\"\"\n",
        "   Извлекает данные из Tag-элемента и добавляет их в словарь.\n",
        "    \n",
        "   Args:\n",
        "      data (dict[str, str|int|float]): Словарь, в который добавляется значение\n",
        "      key (str): Ключ для записи значения в словарь\n",
        "      element (Tag|None): HTML-элемент BeautifulSoup Tag или None\n",
        "      data_type (str): Тип извлекаемых данных: 'text', 'number' или 'rating'\n",
        "    \n",
        "   Returns:\n",
        "      None: Функция модифицирует переданный словарь data\n",
        "    \n",
        "   Notes:\n",
        "      - Для data_type 'text': извлекает текстовое содержимое элемента\n",
        "      - Для data_type 'number': ищет числовое значение в тексте с помощью регулярного выражения\n",
        "      - Для data_type 'rating': определяет рейтинг по второму слову в названии класса (0-5 звезд)\n",
        "      - Если передан неверный аргумент element, значение в словаре не меняется\n",
        "    \"\"\"\n",
        "   if not element:\n",
        "      return\n",
        "   elif data_type not in ('text', 'number', 'rating'):\n",
        "      return\n",
        "   elif data_type == 'text':\n",
        "      data[key] = element.text.strip()\n",
        "   elif data_type == 'number':\n",
        "      match = re.search(_number_pattern, element.text)\n",
        "      if match:\n",
        "         data[key] = float(match.group()) if '.' in match.group() else int(match.group())\n",
        "   elif data_type == 'rating':\n",
        "      stars_count = ('zero', 'one', 'two', 'three', 'four', 'five')\n",
        "      rating = element['class'][1].lower()\n",
        "      if rating in stars_count:\n",
        "         data[key] = stars_count.index(rating)\n",
        "\n",
        "def get_rows(parent: Tag) -> dict[str, str]:\n",
        "   \"\"\"\n",
        "    Извлекает данные из таблицы и возвращает в виде словаря.\n",
        "    \n",
        "    Args:\n",
        "        parent: Родительский Tag-элемент, содержащий таблицу\n",
        "    \n",
        "    Returns:\n",
        "        dict: Словарь, где ключи - тексты из ячеек <th>, \n",
        "              значения - тексты из соответствующих ячеек <td>\n",
        "    \"\"\"\n",
        "   rows = {}\n",
        "   for row in parent.find_all('tr'):\n",
        "      if type(row) != Tag:\n",
        "         continue\n",
        "      key   = get_tag(row, 'th')\n",
        "      value = get_tag(row, 'td')\n",
        "      if key:\n",
        "         _set_dict_value(rows, key.text, value, 'text')\n",
        "         \n",
        "   return rows\n",
        "\n",
        "def get_book_data(book_url: str) -> dict[str, str|int|float|dict[str, str]]:\n",
        "   \"\"\"\n",
        "    Извлекает данные о книге с веб-страницы.\n",
        "    \n",
        "    Args:\n",
        "        book_url (str): URL-адрес страницы книги для парсинга\n",
        "    \n",
        "    Returns:\n",
        "        dict: Словарь с данными о книге, содержащий:\n",
        "            - title (str): Название книги\n",
        "            - price (int|float): Цена книги\n",
        "            - rating (int): Рейтинг от 0 до 5\n",
        "            - available (int): Количество доступных экземпляров\n",
        "            - description (str): Описание книги\n",
        "            - additional_info (dict): Дополнительная информация из таблицы\n",
        "    \"\"\"\n",
        "\n",
        "   # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
        "   data = {\n",
        "      'title': '',\n",
        "      'price': 0, \n",
        "      'rating': 0, \n",
        "      'available': 0, \n",
        "      'description': '', \n",
        "      'additional_info': {}\n",
        "      }\n",
        "\n",
        "   response = requests.get(book_url) \n",
        "   response.encoding = 'utf-8'\n",
        "\n",
        "   # Выбрасывает исключение, если запрос неудачный (код начинается не с 2*)  \n",
        "   response.raise_for_status()\n",
        "\n",
        "   soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "   data_root = get_tag(soup, 'article', 'product_page')\n",
        "\n",
        "   if not data_root:\n",
        "      return data\n",
        "\n",
        "   main_data = get_tag(data_root , 'div', _main_data_pattern)\n",
        "\n",
        "   if not main_data:\n",
        "      return data\n",
        "\n",
        "   title_elem        = get_tag(main_data, 'h1')\n",
        "   description_elem  = get_tag(data_root, 'p')\n",
        "   rating_elem       = get_tag(main_data, 'p', _rating_pattern)\n",
        "   price_elem        = get_tag(main_data, 'p', 'price_color')\n",
        "   available_elem    = get_tag(main_data, 'p', 'instock availability')\n",
        "\n",
        "   _set_dict_value(data, 'title'       , title_elem      , 'text')\n",
        "   _set_dict_value(data, 'description' , description_elem, 'text')\n",
        "   _set_dict_value(data, 'price'       , price_elem      , 'number')\n",
        "   _set_dict_value(data, 'available'   , available_elem  , 'number')\n",
        "   _set_dict_value(data, 'rating'      , rating_elem     , 'rating')\n",
        "\n",
        "   table = get_tag(data_root, 'table', 'table table-striped')\n",
        "\n",
        "   if table:\n",
        "      data['additional_info'] = get_rows(table)\n",
        "\n",
        "   return data\n",
        "   # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "moRSO9Itp1LT",
      "metadata": {
        "id": "moRSO9Itp1LT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': 'A Light in the Attic',\n",
              " 'price': 51.77,\n",
              " 'rating': 3,\n",
              " 'available': 22,\n",
              " 'description': \"It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love th It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love that Silverstein. Need proof of his genius? RockabyeRockabye baby, in the treetopDon't you know a treetopIs no safe place to rock?And who put you up there,And your cradle, too?Baby, I think someone down here'sGot it in for you. Shel, you never sounded so good. ...more\",\n",
              " 'additional_info': {'UPC': 'a897fe39b1053632',\n",
              "  'Product Type': 'Books',\n",
              "  'Price (excl. tax)': '£51.77',\n",
              "  'Price (incl. tax)': '£51.77',\n",
              "  'Tax': '£0.00',\n",
              "  'Availability': 'In stock (22 available)',\n",
              "  'Number of reviews': '0'}}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Используйте для самопроверки\n",
        "book_url = 'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'\n",
        "#book_url = 'https://books.toscrape.com/catalogue/the-bridge-to-consciousness-im-writing-the-bridge-between-science-and-our-old-and-new-beliefs_840/index.html'\n",
        "#cProfile.run('get_book_data(book_url)')\n",
        "get_book_data(book_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u601Q4evosq6",
      "metadata": {
        "id": "u601Q4evosq6"
      },
      "source": [
        "## Задание 2. Сбор данных обо всех книгах (20 баллов)\n",
        "\n",
        "Создайте функцию `scrape_books`, которая будет проходиться по всем страницам из каталога (вида `http://books.toscrape.com/catalogue/page-{N}.html`) и осуществлять парсинг всех страниц в цикле, используя ранее написанную `get_book_data`.\n",
        "\n",
        "Добавьте аргумент-флаг, который будет отвечать за сохранение результата в файл: если он будет равен `True`, то информация сохранится в ту же папку в файл `books_data.txt`; иначе шаг сохранения будет пропущен.\n",
        "\n",
        "**Также не забывайте про соблюдение PEP-8**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "kk78l6oDkdxl",
      "metadata": {
        "id": "kk78l6oDkdxl"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'BeautifulSoup' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Корневая ссылка для парсинга и скрапинга книг\u001b[39;00m\n\u001b[0;32m      2\u001b[0m _root_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://books.toscrape.com/catalogue/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_page_soup\u001b[39m(page_number: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mBeautifulSoup\u001b[49m:\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    Получает HTML-страницу каталога и возвращает объект BeautifulSoup.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m        requests.HTTPError: Если HTTP-запрос завершился с ошибкой\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_root_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mpage-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'BeautifulSoup' is not defined"
          ]
        }
      ],
      "source": [
        "# Корневая ссылка для парсинга и скрапинга книг\n",
        "_root_url = 'https://books.toscrape.com/catalogue/'\n",
        "\n",
        "def _get_page_soup(page_number: int) -> BeautifulSoup:\n",
        "    \"\"\"\n",
        "    Получает HTML-страницу каталога и возвращает объект BeautifulSoup.\n",
        "    \n",
        "    Args:\n",
        "        page_number (int): Номер страницы каталога для загрузки\n",
        "    \n",
        "    Returns:\n",
        "        BeautifulSoup: Объект для парсинга HTML-страницы\n",
        "    \n",
        "    Raises:\n",
        "        requests.HTTPError: Если HTTP-запрос завершился с ошибкой\n",
        "    \"\"\"\n",
        "    response = requests.get(f'{_root_url}page-{page_number}.html')\n",
        "    # Выбрасывает исключение, если запрос неудачный (код начинается не с 2*)\n",
        "    response.raise_for_status()\n",
        "    return BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "def _get_pages_count() -> int:\n",
        "    \"\"\"\n",
        "    Определяет количество страниц в каталоге.\n",
        "    \n",
        "    Returns:\n",
        "        int: Общее количество страниц или 0 при ошибке\n",
        "    \"\"\"\n",
        "    try:\n",
        "        soup = _get_page_soup(1)\n",
        "    except:\n",
        "        return 0\n",
        "    \n",
        "    counter_elem = get_tag(soup, 'li', 'current')\n",
        "    \n",
        "    if not counter_elem:\n",
        "        return 0\n",
        "    \n",
        "    pattern = re.compile('of (\\d+)')\n",
        "    match = re.search(pattern, counter_elem.text)\n",
        "\n",
        "    return int(match.group(1)) if match else 0\n",
        "\n",
        "\n",
        "def _parse_page(page_number: int,  books_data: list[dict], pbar: tqdm|None = None) -> None:\n",
        "    \"\"\"\n",
        "    Парсит страницу каталога и добавляет данные книг в список.\n",
        "    Функция используется для работы в многопоточном режиме.\n",
        "    \n",
        "    Args:\n",
        "        page_number (int): Номер страницы каталога для парсинга\n",
        "        books_data (list[dict]): Список для добавления данных о книгах\n",
        "        pbar (tqdm): Прогресс-бар для обновления статуса выполнения\n",
        "    \"\"\"\n",
        "    try: \n",
        "        soup = _get_page_soup(page_number)\n",
        "    except:\n",
        "        return\n",
        "\n",
        "    books_container = get_tag(soup, 'ol', 'row')\n",
        "\n",
        "    if not books_container:\n",
        "        return\n",
        "\n",
        "    for heading in books_container.find_all('h3'):\n",
        "        \n",
        "        if type(heading) != Tag:\n",
        "            continue\n",
        "        \n",
        "        link = get_tag(heading, 'a')\n",
        "       \n",
        "        if not link:\n",
        "            continue\n",
        "        \n",
        "        href = link['href'] \n",
        "\n",
        "        if not href:\n",
        "            continue\n",
        "\n",
        "        url = _root_url + str(href)\n",
        "\n",
        "        books_data.append(get_book_data(url))\n",
        "\n",
        "    if pbar:\n",
        "        pbar.update(1)\n",
        "\n",
        "\n",
        "def scrape_books(is_save=False) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Собирает данные о всех книгах из каталога с использованием многопоточности.\n",
        "    \n",
        "    Args:\n",
        "        is_save (bool, optional): Сохранять ли данные в файл. По умолчанию False.\n",
        "    \n",
        "    Returns:\n",
        "        list[dict]: Список словарей с данными о книгах\n",
        "    \n",
        "    Process:\n",
        "        - Определяет общее количество страниц в каталоге\n",
        "        - Обрабатывает страницы параллельно в нескольких потоках\n",
        "        - Сохраняет данные в файл при необходимости\n",
        "        - Отображает прогресс выполнения через tqdm\n",
        "    \"\"\"\n",
        "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
        "    \n",
        "    # Количество потоков. В одном потоке обрабатывается одна страница\n",
        "    threads_number = 25\n",
        "\n",
        "    # Список, в который будут добавляться распрасенные данные книг\n",
        "    books_data = []\n",
        "\n",
        "    # Количество страниц\n",
        "    pages_count = _get_pages_count()\n",
        "    \n",
        "    with tqdm(total=pages_count, desc='scraping pages') as pbar:\n",
        "\n",
        "        for page_number in range(1, pages_count + 1, threads_number):\n",
        "            \n",
        "            threads = []\n",
        "\n",
        "            for shift in range(threads_number):\n",
        "                if page_number + shift > pages_count:\n",
        "                    break\n",
        "                threads.append(\n",
        "                    threading.Thread(\n",
        "                        target=_parse_page,\n",
        "                        args=(page_number + shift, books_data, pbar))\n",
        "                    ) \n",
        "\n",
        "            for thread in threads:\n",
        "                thread.start()\n",
        "\n",
        "            for thread in threads:\n",
        "                thread.join()\n",
        "\n",
        "    if is_save:\n",
        "        with open('books_data.txt', 'w', encoding='utf-8') as f:\n",
        "            f.write(json.dumps(books_data, indent=4))\n",
        "\n",
        "    return books_data\n",
        "    # КОНЕЦ ВАШЕГО РЕШЕНИЯ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Bt7mrXcbkj5Q",
      "metadata": {
        "id": "Bt7mrXcbkj5Q"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'scrape_books' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Проверка работоспособности функции\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_books\u001b[49m(is_save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# Допишите ваши аргументы\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res), \u001b[38;5;28mlen\u001b[39m(res)) \u001b[38;5;66;03m# и проверки\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Проверим количество уникальных названий книг\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'scrape_books' is not defined"
          ]
        }
      ],
      "source": [
        "# Проверка работоспособности функции\n",
        "res = scrape_books(is_save=True) # Допишите ваши аргументы\n",
        "print(type(res), len(res)) # и проверки\n",
        "\n",
        "# Проверим количество уникальных названий книг\n",
        "titles = set(d['title'] for d in res)\n",
        "print(len(titles)) # Результат = 999 названий\n",
        "\n",
        "# Убедимся, что есть книги с одинаковыми названиями\n",
        "l = []\n",
        "for d in res:\n",
        "    if l.count(d['title']):\n",
        "        print(d['title'])\n",
        "    l.append(d['title'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z5fd728nl8a8",
      "metadata": {
        "id": "z5fd728nl8a8"
      },
      "source": [
        "## Задание 3. Настройка регулярной выгрузки (10 баллов)\n",
        "\n",
        "Настройте автоматический запуск функции сбора данных каждый день в 19:00.\n",
        "Для автоматизации используйте библиотеку `schedule`. Функция должна запускаться в указанное время и сохранять обновленные данные в текстовый файл.\n",
        "\n",
        "\n",
        "\n",
        "Бесконечный цикл должен обеспечивать постоянное ожидание времени для запуска задачи и выполнять ее по расписанию. Однако чтобы не перегружать систему, стоит подумать о том, чтобы выполнять проверку нужного времени не постоянно, а раз в какой-то промежуток. В этом вам может помочь `time.sleep(...)`.\n",
        "\n",
        "Проверьте работоспособность кода локально на любом времени чч:мм.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SajRRCj4n8BZ",
      "metadata": {
        "id": "SajRRCj4n8BZ"
      },
      "outputs": [],
      "source": [
        "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
        "\n",
        "def run_autoscreping(start_time = '19:00', sleeping_time = 60) -> None:\n",
        "    \"\"\"\n",
        "    Запускает автоматический парсинг книг по расписанию.\n",
        "    \n",
        "    Args:\n",
        "        start_time (str): Время запуска парсинга в формате 'HH:MM'. По умолчанию '19:00'\n",
        "        sleeping_time (int): Интервал проверки расписания в секундах. По умолчанию 60 секунд\n",
        "    \"\"\"\n",
        "    schedule.every().day.at(start_time).do(scrape_books, True)\n",
        "    while True:\n",
        "        schedule.run_pending()\n",
        "        time.sleep(sleeping_time)\n",
        "\n",
        "\n",
        "# Запустите код, как он есть, для установки расписания согласно заданию\n",
        "is_test = False\n",
        "\n",
        "# Раскомментируйте строку ниже, если хотите выполнить тест\n",
        "#is_test = True \n",
        "\n",
        "if is_test:\n",
        "    # Код установит сбор данных сбор данных через минуту от текущего времени\n",
        "    current_time_plus_a_minute = time.strftime('%H:%M', time.localtime(time.time() + 60))\n",
        "    run_autoscreping(current_time_plus_a_minute)\n",
        "else:\n",
        "    run_autoscreping()\n",
        "\n",
        "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XFiPtEyaoLxq",
      "metadata": {
        "id": "XFiPtEyaoLxq"
      },
      "source": [
        "## Задание 4. Написание автотестов (15 баллов)\n",
        "\n",
        "Создайте минимум три автотеста для ключевых функций парсинга — например, `get_book_data` и `scrape_books`. Идеи проверок (можете использовать свои):\n",
        "\n",
        "* данные о книге возвращаются в виде словаря с нужными ключами;\n",
        "* список ссылок или количество собранных книг соответствует ожиданиям;\n",
        "* значения отдельных полей (например, `title`) корректны.\n",
        "\n",
        "Оформите тесты в отдельном скрипте `tests/test_scraper.py`, используйте библиотеку `pytest`. Убедитесь, что тесты проходят успешно при запуске из терминала командой `pytest`.\n",
        "\n",
        "Также выведите результат их выполнения в ячейке ниже.\n",
        "\n",
        "**Не забывайте про соблюдение PEP-8**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "lBFAw4b3z8QY",
      "metadata": {
        "id": "lBFAw4b3z8QY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts =============================\u001b[0m\n",
            "platform win32 -- Python 3.10.6, pytest-8.4.2, pluggy-1.6.0 -- C:\\Users\\ardd\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\n",
            "cachedir: .pytest_cache\n",
            "rootdir: d:\\python\\mipt\\books_scraper\n",
            "plugins: anyio-4.10.0, mock-3.15.1\n",
            "\u001b[1mcollecting ... \u001b[0mcollected 5 items\n",
            "\n",
            "..\\tests\\test_scraper.py::test_get_book_data \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 20%]\u001b[0m\n",
            "..\\tests\\test_scraper.py::test_scrape_books \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 40%]\u001b[0m\n",
            "..\\tests\\test_scraper.py::test_scrape_books_with_save_file \u001b[32mPASSED\u001b[0m\u001b[32m        [ 60%]\u001b[0m\n",
            "..\\tests\\test_scraper.py::test_check_file_data \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 80%]\u001b[0m\n",
            "..\\tests\\test_scraper.py::test_remove_test_data \u001b[32mPASSED\u001b[0m\u001b[32m                   [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================= \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 51.12s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Ячейка для демонстрации работоспособности\n",
        "# Сам код напишите в отдельном скрипте\n",
        "\n",
        "! pytest ../tests/test_scraper.py -v"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cRSQlHfRtOdN",
      "metadata": {
        "id": "cRSQlHfRtOdN"
      },
      "source": [
        "## Задание 5. Оформление проекта на GitHub и работа с Git (35 баллов)\n",
        "\n",
        "В этом задании нужно воспользоваться системой контроля версий Git и платформой GitHub для хранения и управления своим проектом. **Ссылку на свой репозиторий пришлите в форме для сдачи ответа.**\n",
        "\n",
        "### Пошаговая инструкция и задания\n",
        "\n",
        "**1. Установите Git на свой компьютер.**\n",
        "\n",
        "* Для Windows: [скачайте установщик](https://git-scm.com/downloads) и выполните установку.\n",
        "* Для macOS:\n",
        "\n",
        "  ```\n",
        "  brew install git\n",
        "  ```\n",
        "* Для Linux:\n",
        "\n",
        "  ```\n",
        "  sudo apt update\n",
        "  sudo apt install git\n",
        "  ```\n",
        "\n",
        "**2. Настройте имя пользователя и email.**\n",
        "\n",
        "Это нужно для подписи ваших коммитов, сделайте в терминале через `git config ...`.\n",
        "\n",
        "**3. Создайте аккаунт на GitHub**, если у вас его еще нет:\n",
        "[https://github.com](https://github.com)\n",
        "\n",
        "**4. Создайте новый репозиторий на GitHub:**\n",
        "\n",
        "* Найдите кнопку **New repository**.\n",
        "* Укажите название, краткое описание, выберите тип **Public** (чтобы мы могли проверить ДЗ).\n",
        "* Не ставьте галочку Initialize this repository with a README.\n",
        "\n",
        "**5. Создайте локальную папку с проектом.** Можно в терминале, можно через UI, это не имеет значения.\n",
        "\n",
        "**6. Инициализируйте Git в этой папке.** Здесь уже придется воспользоваться некоторой командой в терминале.\n",
        "\n",
        "**7. Привяжите локальный репозиторий к удаленному на GitHub.**\n",
        "\n",
        "**8. Создайте ветку разработки.** По умолчанию вы будете находиться в ветке `main`, создайте и переключитесь на ветку `hw-books-parser`.\n",
        "\n",
        "**9. Добавьте в проект следующие файлы и папки:**\n",
        "\n",
        "* `scraper.py` — ваш основной скрипт для сбора данных.\n",
        "* `README.md` — файл с кратким описанием проекта:\n",
        "\n",
        "  * цель;\n",
        "  * инструкции по запуску;\n",
        "  * список используемых библиотек.\n",
        "* `requirements.txt` — файл со списком зависимостей, необходимых для проекта (не присылайте все из глобального окружения, создайте изолированную виртуальную среду, добавьте в нее все нужное для проекта и получите список библиотек через `pip freeze`).\n",
        "* `artifacts/` — папка с результатами парсинга (`books_data.txt` — полностью или его часть, если весь не поместится на GitHub).\n",
        "* `notebooks/` — папка с заполненным ноутбуком `HW_03_python_ds_2025.ipynb` и запущенными ячейками с выводами на экран.\n",
        "* `tests/` — папка с тестами на `pytest`, оформите их в формате скрипта(-ов) с расширением `.py`.\n",
        "* `.gitignore` — стандартный файл, который позволит исключить временные файлы при добавлении в отслеживаемые (например, `__pycache__/`, `.DS_Store`, `*.pyc`, `venv/` и др.).\n",
        "\n",
        "\n",
        "**10. Сделайте коммит.**\n",
        "\n",
        "**11. Отправьте свою ветку на GitHub.**\n",
        "\n",
        "**12. Создайте Pull Request:**\n",
        "\n",
        "* Перейдите в репозиторий на GitHub.\n",
        "* Нажмите кнопку **Compare & pull request**.\n",
        "* Укажите, что было добавлено, и нажмите **Create pull request**.\n",
        "\n",
        "**13. Выполните слияние Pull Request:**\n",
        "\n",
        "* Убедитесь, что нет конфликтов.\n",
        "* Нажмите **Merge pull request**, затем **Confirm merge**.\n",
        "\n",
        "**14. Скачайте изменения из основной ветки локально.**\n",
        "\n",
        "\n",
        "\n",
        "### Требования к итоговому репозиторию\n",
        "\n",
        "* Файл `scraper.py` с рабочим кодом парсера.\n",
        "* `README.md` с описанием проекта и инструкцией по запуску.\n",
        "* Папка `artifacts/` с результатом сбора данных (`.txt` файл).\n",
        "* Папка `tests/` с тестами на `pytest`.\n",
        "* Папка `notebooks/` с заполненным ноутбуком `HW_03_python_ds_2025.ipynb`.\n",
        "* Pull Request с комментарием из ветки `hw-books-parser` в ветку `main`.\n",
        "* Примерная структура:\n",
        "\n",
        "  ```\n",
        "  books_scraper/\n",
        "  ├── artifacts/\n",
        "  │   └── books_data.txt\n",
        "  ├── notebooks/\n",
        "  │   └── HW_03_python_ds_2025.ipynb\n",
        "  ├── scraper.py\n",
        "  ├── README.md\n",
        "  ├── tests/\n",
        "  │   └── test_scraper.py\n",
        "  ├── .gitignore\n",
        "  └── requirements.txt\n",
        "  ```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
